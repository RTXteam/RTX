pipeline {
    options {
        timestamps()
        skipDefaultCheckout()
        disableConcurrentBuilds()
    }
    agent {
        node { label 'transltr-ci-build-node-03' }
    }
    parameters {
        string(name: 'BUILD_VERSION', defaultValue: '', description: 'The build version to deploy (optional)')
        string(name: 'AWS_REGION', defaultValue: 'us-east-1', description: 'AWS Region to deploy')
    }
    triggers {
        pollSCM('H/5 * * * *')
    }
    environment {
        DOCKER_REPO_NAME = "translator-rtx-arax"
        KUBERNETES_BLUE_CLUSTER_NAME = "translator-eks-ci-blue-cluster"
        KUBERNETES_GREEN_CLUSTER_NAME = "translator-eks-ci-green-cluster"
        NAMESPACE = "rtx"
        SECRET_NAME = "sftp-ssh-key"
        CONFIG_JSON_CONFIGMAP = "configv2"
    }
    stages {
      stage('Build Version'){
          when { expression { return !params.BUILD_VERSION } }
          steps{
              script {
                  BUILD_VERSION_GENERATED = VersionNumber(
                      versionNumberString: 'v${BUILD_YEAR, XX}.${BUILD_MONTH, XX}${BUILD_DAY, XX}.${BUILDS_TODAY}',
                      projectStartDate:    '1970-01-01',
                      skipFailedBuilds:    true)
                  currentBuild.displayName = BUILD_VERSION_GENERATED
                  env.BUILD_VERSION = BUILD_VERSION_GENERATED
                  env.BUILD = 'true'
              }
          }
      }
      stage('Checkout source code') {
          steps {
              cleanWs()
              checkout scm
          }
      }
      stage('Build and Push Docker Image') {
         when { expression { return env.BUILD == 'true' }}
          steps {
            configFileProvider([
                configFile(fileId: 'configv2.json', targetLocation: 'DockerBuild/configv2.json')
            ]){
                script {
                    docker.build(env.DOCKER_REPO_NAME, "--no-cache ./DockerBuild/")
                    docker.withRegistry('https://853771734544.dkr.ecr.us-east-1.amazonaws.com', 'ecr:us-east-1:aws-ifx-deploy') {
                        docker.image(env.DOCKER_REPO_NAME).push("${BUILD_VERSION}")
                    }
                }
            }
          }
      }
      // stage('Create K8S Secret sftp-ssh-key From Jenkins Secrets') {
      //   steps {
      //     script {
      //       withCredentials([
      //         sshUserPrivateKey(
      //           credentialsId: 'team-expander-ops-sshkey',
      //           keyFileVariable: 'SECRET_FILE',
      //           usernameVariable: 'username')
      //       ]) {
      //         withAWS(credentials:'aws-ifx-deploy') 
      //         {
      //           sh '''
      //             aws --region ${AWS_REGION} eks update-kubeconfig --name ${KUBERNETES_BLUE_CLUSTER_NAME}
      //             # delete if exists
      //             if kubectl -n ${NAMESPACE} get secrets ${SECRET_NAME}; then
      //               echo "$$$$$ got secret"
      //               kubectl -n ${NAMESPACE} delete secret ${SECRET_NAME}
      //             else
      //               echo "$$$$$ no secret, creating now"
      //             fi
      //             kubectl -n ${NAMESPACE} create secret generic ${SECRET_NAME} --from-file=${SECRET_FILE}
      //           '''
      //         }
      //       }
      //     }
      //   }
      // }
      // stage('Create K8S ConfigMap From configv2.json') {
      //   steps {
      //     configFileProvider([
      //         configFile(fileId: 'configv2.json', targetLocation: 'deploy/config/configv2.json')
      //     ]){
      //       script {
      //         withCredentials([
      //           sshUserPrivateKey(
      //             credentialsId: 'team-expander-ops-sshkey',
      //             keyFileVariable: 'SECRET_FILE',
      //             usernameVariable: 'username')
      //         ]) {
      //           withAWS(credentials:'aws-ifx-deploy') 
      //           {
      //             sh '''
      //               aws --region ${AWS_REGION} eks update-kubeconfig --name ${KUBERNETES_BLUE_CLUSTER_NAME}
      //               # delete if exists
      //               if kubectl -n ${NAMESPACE} get configmaps ${CONFIG_JSON_CONFIGMAP}; then
      //                 echo "$$$$$ got configv2 ConfigMap"
      //                 kubectl -n ${NAMESPACE} delete configmaps ${CONFIG_JSON_CONFIGMAP}
      //               else
      //                 echo "$$$$$ no configv2 ConfigMap, creating now"
      //               fi
      //               kubectl -n ${NAMESPACE} create configmap ${CONFIG_JSON_CONFIGMAP} --from-file ./deploy/configv2.json
      //             '''
      //           }
      //         }
      //       }
      //     }     
      //   }
      // }
      stage('Deploy to AWS EKS Blue') {
          steps {
              configFileProvider([
                  configFile(fileId: 'configv2.json', targetLocation: 'deploy/config/configv2.json')
              ]){
                  withCredentials([
                    sshUserPrivateKey(
                      credentialsId: 'team-expander-ops-sshkey',
                      keyFileVariable: 'SECRET')
                  ]){
                    withAWS(credentials:'aws-ifx-deploy') 
                    {
                        sh '''
                        # Need to save the credential to a file with base64 encoded under deploy/secret
                        echo "$SECRET" | base64 >> deploy/secret/team-expander-ops-sshkey
                        aws --region ${AWS_REGION} eks update-kubeconfig --name ${KUBERNETES_BLUE_CLUSTER_NAME}
                        # cd deploy && /bin/bash deploy.sh
                        # aws --region ${AWS_REGION} sts get-caller-identity
                        '''
                    }
                  } 
              }
          }
      }
    }
}
