#!/bin/env python3
"""
This script creates a 'meta knowledge graph' (per TRAPI) and records node neighbor counts by category (in the
kg2c.sqlite file generated by create_kg2c_files.py). It uses the 'lite' KG2c JSON file to derive this meta info.
"""
import argparse
import json
import sqlite3
import time
from collections import defaultdict
from datetime import datetime
from typing import Dict, List


def _print_log_message(message: str):
    current_time = datetime.utcfromtimestamp(time.time()).strftime('%H:%M:%S')
    print(f"{current_time}: {message}")


def serialize_with_sets(obj: any) -> any:
    # Thank you https://stackoverflow.com/a/60544597
    if isinstance(obj, set):
        return list(obj)
    else:
        return obj


def _get_expanded_predicates(predicate: str) -> List[str]:
    # TODO: Use biolink model here to get ancestors and inverses of predicate
    return [predicate]


def build_meta_map(nodes_by_id: Dict[str, Dict[str, any]], edges_by_id: Dict[str, Dict[str, any]],
                   output_metamap_file_name: str, label_property_name: str, is_test: bool):
    _print_log_message("Gathering all meta triples..")
    meta_triples = set()
    for edge in edges_by_id.values():
        subject_node_id = edge["subject"]
        object_node_id = edge["object"]
        if not is_test or (subject_node_id in nodes_by_id and object_node_id in nodes_by_id):
            subject_node = nodes_by_id[subject_node_id]
            object_node = nodes_by_id[object_node_id]
            subject_categories = subject_node[label_property_name]
            object_categories = object_node[label_property_name]
            predicates = _get_expanded_predicates(edge["predicate"])
            for subject_category in subject_categories:
                for predicate in predicates:
                    for object_category in object_categories:
                        meta_triples.add((subject_category, predicate, object_category))
    meta_edges = [{"subject": triple[0], "predicate": triple[1], "object": triple[2]} for triple in meta_triples]

    _print_log_message("Gathering all meta nodes..")
    meta_nodes = defaultdict(lambda: defaultdict(lambda: set()))
    for node_id, node in nodes_by_id.items():
        prefix = node_id.split(":")[0]
        categories = node[label_property_name]
        for category in categories:
            meta_nodes[category]["id_prefixes"].add(prefix)

    _print_log_message("Saving metamap to JSON file..")
    metamap = {"nodes": meta_nodes, "edges": meta_edges}
    with open(output_metamap_file_name, "w+") as metamap_file:
        json.dump(metamap, metamap_file, default=serialize_with_sets)


def add_neighbor_counts_to_sqlite(nodes_by_id: Dict[str, Dict[str, any]], edges_by_id: Dict[str, Dict[str, any]],
                                  label_property_name: str, sqlite_file_name: str, is_test: bool):
    _print_log_message("Counting up node neighbors by category..")
    # First gather neighbors of each node by label/category
    neighbors_by_label = defaultdict(lambda: defaultdict(lambda: set()))
    for edge in edges_by_id.values():
        subject_node_id = edge["subject"]
        object_node_id = edge["object"]
        if not is_test or (subject_node_id in nodes_by_id and object_node_id in nodes_by_id):
            subject_node = nodes_by_id[subject_node_id]
            object_node = nodes_by_id[object_node_id]
            for label in object_node[label_property_name]:
                neighbors_by_label[subject_node_id][label].add(object_node_id)
            for label in subject_node[label_property_name]:
                neighbors_by_label[object_node_id][label].add(subject_node_id)

    # Then record only the counts of neighbors per label/category
    neighbor_counts = defaultdict(dict)
    for node_id, neighbors_dict in neighbors_by_label.items():
        for label, neighbor_ids in neighbors_dict.items():
            neighbor_counts[node_id][label] = len(neighbor_ids)

    # Then write these counts to the sqlite file
    _print_log_message(f"Saving neighbor counts (for {len(neighbor_counts)} nodes) to sqlite..")
    connection = sqlite3.connect(sqlite_file_name)
    connection.execute("DROP TABLE IF EXISTS neighbors")
    connection.execute("CREATE TABLE neighbors (id TEXT, neighbor_counts TEXT)")
    rows = [(node_id, json.dumps(neighbor_counts)) for node_id, neighbor_counts in neighbor_counts.items()]
    connection.executemany(f"INSERT INTO neighbors (id, neighbor_counts) VALUES (?, ?)", rows)
    connection.execute("CREATE UNIQUE INDEX node_neighbor_index ON neighbors (id)")
    connection.commit()
    cursor = connection.execute(f"SELECT COUNT(*) FROM neighbors")
    _print_log_message(f"Done adding neighbor counts to sqlite; neighbors table contains {cursor.fetchone()[0]} rows")
    cursor.close()
    connection.close()


def main():
    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--test', dest='test', action='store_true', default=False)
    args = arg_parser.parse_args()

    input_kg_file_name = f"kg2c_lite{'_test' if args.test else ''}.json"
    output_metamap_file_name = f"kg2c_metamap{'_test' if args.test else ''}.json"
    sqlite_file_name = f"kg2c{'_test' if args.test else ''}.sqlite"
    label_property_name = "expanded_categories"

    start = time.time()
    with open(input_kg_file_name, "r") as input_kg_file:
        _print_log_message(f"Loading {input_kg_file_name} into memory..")
        kg2c_dict = json.load(input_kg_file)
        nodes_by_id = {node["id"]: node for node in kg2c_dict["nodes"]}
        edges_by_id = {edge["id"]: edge for edge in kg2c_dict["edges"]}
        del kg2c_dict

    build_meta_map(nodes_by_id, edges_by_id, output_metamap_file_name, label_property_name, args.test)
    add_neighbor_counts_to_sqlite(nodes_by_id, edges_by_id, label_property_name, sqlite_file_name, args.test)

    _print_log_message(f"Done! Took {round((time.time() - start) / 60, 1)} minutes.")


if __name__ == "__main__":
    main()
